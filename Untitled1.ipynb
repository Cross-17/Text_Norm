{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Crossbell\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_classify_train_data(np_file,csv_file):\n",
    "    if os.path.exists(np_file) == True:\n",
    "       temp = np.load(np_file)\n",
    "       return temp['x_train'],temp['y_train'],temp['label']\n",
    "    else:\n",
    "        num_features = 9 #每个 word 取前 5 后 4 个字符来编码\n",
    "        train=pd.read_csv(csv_file)\n",
    "        tmp=pd.factorize(train['class'])\n",
    "        y_train,label=tmp[0].astype(np.int8),tmp[1].values\n",
    "        num_train=len(y_train)\n",
    "        train['before']=train['before'].astype(np.str)\n",
    "        x_train=np.zeros([num_train,num_features],np.int8)\n",
    "        feature=np.zeros([num_train,7],np.int8)# 人工提取的特征\n",
    "        list1=('a','e','i','o','u')# 元音\n",
    "        list2=('+','-','*','//','%')# 数学运算符\n",
    "        for word,row in zip(train['before'].values,range(num_train)):\n",
    "            if(len(word)>=num_features):\n",
    "                for c,col in zip(word[:5],range(5)):\n",
    "                    x_train[row,col]=ord(c)\n",
    "                for c,col in zip(word[-4:],range(5,9)):\n",
    "                    x_train[row,col]=ord(c)\n",
    "            else:\n",
    "                for c,col in zip(word,range(num_features)):\n",
    "                    x_train[row,col]=ord(c)\n",
    "            feature[row, 3] =len(word) # 统计字符串的长度\n",
    "            dotflag=0\n",
    "            for c in word:\n",
    "                if c.isdigit():feature[row,0]+=1# 统计数字的个数\n",
    "                if c.isupper():feature[row,1]+=1# 统计大写字母的个数\n",
    "                if c.isalnum()!=True:feature[row,2]+=1# 统计非字母和数字的个数\n",
    "                if c in list1:feature[row,4]+=1# 统计元音的个数\n",
    "                if c=='.': dotflag=1\n",
    "                elif dotflag==1:#  . 后面跟字母置 1 ，数字置 2，其他置 3\n",
    "                    dotflag = 0\n",
    "                    if c.isdigit():feature[row,5]+=10\n",
    "                    elif c.isalpha():feature[row,5]+=100\n",
    "                    else:feature[row,5]+=1000\n",
    "                if c in list2:feature[row,6]+=1# 统计数学运算符的个数\n",
    "\n",
    "        # 掐头去尾，结合上文 2 单词，下文 1 个单词\n",
    "        num_train-=3\n",
    "        y_train=y_train[2:-1]\n",
    "        x_train=np.concatenate((x_train[:-3],x_train[1:-2],x_train[2:-1],x_train[3:],feature[2:-1]),axis=1)\n",
    "        np.savez(np_file,x_train=x_train, y_train=y_train, label=label)\n",
    "        return x_train, y_train, label\n",
    "\n",
    "def get_classify_test_data(np_file,csv_file):\n",
    "    test=pd.read_csv(csv_file)\n",
    "    if os.path.exists(np_file) == True:\n",
    "       temp = np.load(np_file)\n",
    "       x_test=temp['x_test']\n",
    "    else:\n",
    "        num_features = 9 #每个 word 取前 5 后 4 个字符来编码\n",
    "        human_feature=7 #人工提取7个特征\n",
    "        num_test=len(test)\n",
    "        test['before']=test['before'].astype(np.str)\n",
    "        x_test=np.zeros([num_test,num_features],np.int8)\n",
    "        feature=np.zeros([num_test,human_feature],np.int8)# 人工提取的特征\n",
    "        list1=('a','e','i','o','u')# 元音\n",
    "        list2=('+','-','*','//','%')# 数学运算符\n",
    "        for word,row in zip(test['before'].values,range(num_test)):\n",
    "            if(len(word)>=num_features):\n",
    "                for c,col in zip(word[:5],range(5)):\n",
    "                    x_test[row,col]=ord(c)\n",
    "                for c,col in zip(word[-4:],range(5,9)):\n",
    "                    x_test[row,col]=ord(c)\n",
    "            else:\n",
    "                for c,col in zip(word,range(num_features)):\n",
    "                    x_test[row,col]=ord(c)\n",
    "            feature[row, 3] =len(word) # 统计字符串的长度\n",
    "            dotflag=0\n",
    "            for c in word:\n",
    "                if c.isdigit():feature[row,0]+=1# 统计数字的个数\n",
    "                if c.isupper():feature[row,1]+=1# 统计大写字母的个数\n",
    "                if c.isalnum()!=True:feature[row,2]+=1# 统计非字母和数字的个数\n",
    "                if c in list1:feature[row,4]+=1# 统计元音的个数\n",
    "                if c=='.': dotflag=1\n",
    "                elif dotflag==1:#  . 后面跟字母置 1 ，数字置 2，其他置 3\n",
    "                    dotflag = 0\n",
    "                    if c.isdigit():feature[row,5]+=10\n",
    "                    elif c.isalpha():feature[row,5]+=100\n",
    "                    else:feature[row,5]+=1000\n",
    "                if c in list2:feature[row,6]+=1# 统计数学运算符的个数\n",
    "\n",
    "        # 开头补上2个单词,结尾补上1个单词，结合上文 2 单词，下文 1 个单词\n",
    "        x_test = np.concatenate((np.zeros([2,num_features],np.int8),x_test,np.zeros([1,num_features],np.int8)),axis=0)\n",
    "        feature = np.concatenate((np.zeros([2,human_feature],np.int8),feature,np.zeros([1,human_feature],np.int8)),axis=0)\n",
    "        x_test=np.concatenate((x_test[:-3],x_test[1:-2],x_test[2:-1],x_test[3:],feature[2:-1]),axis=1)\n",
    "        np.savez(np_file,x_test=x_test)\n",
    "    return test, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9918438L, 43L)\n",
      "[0]\ttrain-merror:0.120224\n",
      "[1]\ttrain-merror:0.497519\n",
      "[2]\ttrain-merror:0.205142\n",
      "[3]\ttrain-merror:0.252915\n",
      "[4]\ttrain-merror:0.147797\n",
      "[5]\ttrain-merror:0.099979\n",
      "[6]\ttrain-merror:0.186730\n",
      "[7]\ttrain-merror:0.154385\n",
      "[8]\ttrain-merror:0.173215\n",
      "[9]\ttrain-merror:0.118270\n",
      "[10]\ttrain-merror:0.107922\n",
      "[11]\ttrain-merror:0.092096\n",
      "[12]\ttrain-merror:0.077121\n",
      "[13]\ttrain-merror:0.075741\n",
      "[14]\ttrain-merror:0.077178\n"
     ]
    }
   ],
   "source": [
    "prehead='input/'\n",
    "train_data_csv='en_train.csv'\n",
    "classify_train_file='classify_train.npz'\n",
    "xgb_model='xgb_model'\n",
    "test_data_csv='en_test.csv'\n",
    "classify_test_file='classify_test.npz'\n",
    "xgb_model2='xgb_model2.dat'\n",
    "classify_test_file2='classify_test2.npz'\n",
    "\n",
    "    # 训练模型\n",
    "x_train,y_train,label=get_classify_train_data(prehead+classify_train_file,prehead+train_data_csv)\n",
    "print(x_train.shape)\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "watchlist = [(dtrain, 'train')]\n",
    "param = {\n",
    "        'eta': 0.3,\n",
    "        'max_depth':10,\n",
    "        'objective':'multi:softmax',\n",
    "        'num_class':len(label),\n",
    "        'eval_metric':'merror',\n",
    "        'subsample': 1,\n",
    "        'colsample_bytree': 1,\n",
    "        'silent':1,\n",
    "        'seed':0,\n",
    "}\n",
    "num_boost_rounds=220\n",
    "model = xgb.train(param, dtrain, num_boost_rounds, watchlist,verbose_eval=1,xgb_model=xgb_model)\n",
    "print('save model ',xgb_model2)\n",
    "pickle.dump(model,open(xgb_model2,'wb'))# 保存模型\n",
    "del x_train,y_train\n",
    "gc.collect()\n",
    "\n",
    "    # 预测 test 上的 class\n",
    "model = pickle.load(open(xgb_model2, \"rb\"))\n",
    "test,x_test=get_classify_test_data(prehead+classify_test_file,prehead+test_data_csv)\n",
    "print(x_test.shape)                                            \n",
    "dtest = xgb.DMatrix(x_test)\n",
    "pred = model.predict(dtest)\n",
    "pred = [label[int(x)] for x in pred]\n",
    "test['class']=pred\n",
    "test.to_csv(os.path.join(prehead, 'test_pred_class.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
